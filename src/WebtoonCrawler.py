import os
import time
import json
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup


class ChromeWebDriverManager:
    """í¬ë¡¬ ë“œë¼ì´ë²„ë¥¼ ìë™ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, headless: bool = False):
        self.headless = headless
        self.driver_path = None
        self.setup_driver()

    def setup_driver(self):
        """ë“œë¼ì´ë²„ë¥¼ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê³  ì„¤ì •í•˜ëŠ” ë©”ì„œë“œ"""
        try:
            self.driver_path = ChromeDriverManager().install()
        except Exception as e:
            print(f"âŒ í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì¹˜ ì˜¤ë¥˜: {e}")
            return

    def get_driver(self):
        """ì„¤ì •ëœ í¬ë¡¬ ë“œë¼ì´ë²„ë¥¼ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œ"""
        if not self.driver_path:
            print("ğŸš¨ í¬ë¡¬ ë“œë¼ì´ë²„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì„¤ì •í•©ë‹ˆë‹¤.")
            self.setup_driver()

        options = Options()
        if self.headless:
            options.add_argument("--headless")

        service = Service(self.driver_path)
        driver = webdriver.Chrome(service=service, options=options)
        return driver


class WebtoonCrawler:
    """ì›¹íˆ° ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•˜ëŠ” í´ë˜ìŠ¤"""

    THUMBNAIL_CLASS = 'Poster__thumbnail_area--gviWY'

    def __init__(self, driver_manager: ChromeWebDriverManager):
        self.driver_manager = driver_manager
        self.driver = driver_manager.get_driver()
        self.data = []

    def get_thumbnail_url(self, soup):
        """ì›¹íˆ° ì¸ë„¤ì¼ URLì„ ì¶”ì¶œí•˜ëŠ” ë©”ì„œë“œ"""
        try:
            img_tag = soup.find('div', {'class': self.THUMBNAIL_CLASS}).find('img')
            return img_tag['src'].strip() if img_tag and 'src' in img_tag.attrs else None
        except Exception:
            return None

    def fetch_webtoon_list(self, url: str):
        """ì›¹íˆ° ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´"""
        try:
            print(f"ğŸŒ ì›¹íˆ° í˜ì´ì§€ ì ‘ì†: {url}")
            self.driver.get(url)
            time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            
            soup = BeautifulSoup(self.driver.page_source, "html.parser")
            thumbnail_url = self.get_thumbnail_url(soup)
            
            if thumbnail_url:
                print(f"ğŸ–¼ï¸ ì¸ë„¤ì¼ URL: {thumbnail_url}")
                self.data.append({"url": url, "thumbnail": thumbnail_url})
            else:
                print("ğŸš¨ ì¸ë„¤ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ğŸš¨ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

    def save_to_json(self, filename="webtoon_data.json"):
        """í¬ë¡¤ë§ëœ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(self.data, f, indent=4, ensure_ascii=False)
        print(f"ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filename}")

    def close(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        self.driver.quit()


# ğŸ“Œ ì‹¤í–‰ ì˜ˆì œ
if __name__ == "__main__":
    driver_manager = ChromeWebDriverManager(headless=True)
    crawler = WebtoonCrawler(driver_manager)

    sample_urls = [
        "https://comic.naver.com/webtoon/list?titleId=747271",
        "https://comic.naver.com/webtoon/list?titleId=769209",
        "https://comic.naver.com/webtoon/list?titleId=776601",
    ]

    for url in sample_urls:
        crawler.fetch_webtoon_list(url)

    crawler.save_to_json()
    crawler.close()